{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 신문기사 데이터 추출 및 CSV 저장\n",
    "이 노트북에서는 GDELT API를 사용하여 특정 키워드에 맞는 신문기사를 추출하고, Newspaper3k 라이브러리를 사용해 각 기사의 본문을 파싱한 후, 이를 CSV 파일로 저장하는 방법을 설명합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 필요한 라이브러리 설치 및 임포트\n",
    "\n",
    "이 단계에서는 필요한 라이브러리들을 설치합니다. gdeltdoc는 GDELT API를 사용하여 기사를 검색할 때 필요하고, newspaper3k는 각 기사에서 본문을 추출할 때 사용됩니다. 또한, pandas 라이브러리를 사용해 데이터를 쉽게 다룰 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gdeltdoc\n",
      "  Downloading gdeltdoc-1.12.0-py3-none-any.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: pandas>=2.2.3 in c:\\users\\yunji\\anaconda3\\envs\\myenv\\lib\\site-packages (from gdeltdoc) (2.3.2)\n",
      "Requirement already satisfied: requests>=2.32.3 in c:\\users\\yunji\\anaconda3\\envs\\myenv\\lib\\site-packages (from gdeltdoc) (2.32.5)\n",
      "Requirement already satisfied: typing-extensions>=4.13.0 in c:\\users\\yunji\\anaconda3\\envs\\myenv\\lib\\site-packages (from gdeltdoc) (4.14.1)\n",
      "Requirement already satisfied: numpy>=1.22.4 in c:\\users\\yunji\\anaconda3\\envs\\myenv\\lib\\site-packages (from pandas>=2.2.3->gdeltdoc) (2.2.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\yunji\\anaconda3\\envs\\myenv\\lib\\site-packages (from pandas>=2.2.3->gdeltdoc) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\yunji\\anaconda3\\envs\\myenv\\lib\\site-packages (from pandas>=2.2.3->gdeltdoc) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\yunji\\anaconda3\\envs\\myenv\\lib\\site-packages (from pandas>=2.2.3->gdeltdoc) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\yunji\\anaconda3\\envs\\myenv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=2.2.3->gdeltdoc) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\yunji\\anaconda3\\envs\\myenv\\lib\\site-packages (from requests>=2.32.3->gdeltdoc) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\yunji\\anaconda3\\envs\\myenv\\lib\\site-packages (from requests>=2.32.3->gdeltdoc) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\yunji\\anaconda3\\envs\\myenv\\lib\\site-packages (from requests>=2.32.3->gdeltdoc) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\yunji\\anaconda3\\envs\\myenv\\lib\\site-packages (from requests>=2.32.3->gdeltdoc) (2025.8.3)\n",
      "Downloading gdeltdoc-1.12.0-py3-none-any.whl (17 kB)\n",
      "Installing collected packages: gdeltdoc\n",
      "Successfully installed gdeltdoc-1.12.0\n",
      "Collecting newspaper3k==0.2.8\n",
      "  Downloading newspaper3k-0.2.8-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: beautifulsoup4>=4.4.1 in c:\\users\\yunji\\anaconda3\\envs\\myenv\\lib\\site-packages (from newspaper3k==0.2.8) (4.13.5)\n",
      "Collecting Pillow>=3.3.0 (from newspaper3k==0.2.8)\n",
      "  Downloading pillow-11.3.0-cp310-cp310-win_amd64.whl.metadata (9.2 kB)\n",
      "Collecting PyYAML>=3.11 (from newspaper3k==0.2.8)\n",
      "  Downloading PyYAML-6.0.2-cp310-cp310-win_amd64.whl.metadata (2.1 kB)\n",
      "Collecting cssselect>=0.9.2 (from newspaper3k==0.2.8)\n",
      "  Downloading cssselect-1.3.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting lxml>=3.6.0 (from newspaper3k==0.2.8)\n",
      "  Downloading lxml-6.0.2-cp310-cp310-win_amd64.whl.metadata (3.7 kB)\n",
      "Collecting nltk>=3.2.1 (from newspaper3k==0.2.8)\n",
      "  Downloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: requests>=2.10.0 in c:\\users\\yunji\\anaconda3\\envs\\myenv\\lib\\site-packages (from newspaper3k==0.2.8) (2.32.5)\n",
      "Collecting feedparser>=5.2.1 (from newspaper3k==0.2.8)\n",
      "  Downloading feedparser-6.0.12-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting tldextract>=2.0.1 (from newspaper3k==0.2.8)\n",
      "  Downloading tldextract-5.3.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting feedfinder2>=0.0.4 (from newspaper3k==0.2.8)\n",
      "  Downloading feedfinder2-0.0.4.tar.gz (3.3 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting jieba3k>=0.35.1 (from newspaper3k==0.2.8)\n",
      "  Downloading jieba3k-0.35.1.zip (7.4 MB)\n",
      "     ---------------------------------------- 0.0/7.4 MB ? eta -:--:--\n",
      "     ---- ----------------------------------- 0.8/7.4 MB 4.2 MB/s eta 0:00:02\n",
      "     ----------- ---------------------------- 2.1/7.4 MB 5.3 MB/s eta 0:00:01\n",
      "     ------------------ --------------------- 3.4/7.4 MB 5.6 MB/s eta 0:00:01\n",
      "     ------------------------ --------------- 4.5/7.4 MB 5.4 MB/s eta 0:00:01\n",
      "     ------------------------------- -------- 5.8/7.4 MB 5.5 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 6.8/7.4 MB 5.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 7.4/7.4 MB 5.2 MB/s  0:00:01\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\users\\yunji\\anaconda3\\envs\\myenv\\lib\\site-packages (from newspaper3k==0.2.8) (2.9.0.post0)\n",
      "Collecting tinysegmenter==0.3 (from newspaper3k==0.2.8)\n",
      "  Downloading tinysegmenter-0.3.tar.gz (16 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\yunji\\anaconda3\\envs\\myenv\\lib\\site-packages (from beautifulsoup4>=4.4.1->newspaper3k==0.2.8) (2.8)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\yunji\\anaconda3\\envs\\myenv\\lib\\site-packages (from beautifulsoup4>=4.4.1->newspaper3k==0.2.8) (4.14.1)\n",
      "Requirement already satisfied: six in c:\\users\\yunji\\anaconda3\\envs\\myenv\\lib\\site-packages (from feedfinder2>=0.0.4->newspaper3k==0.2.8) (1.17.0)\n",
      "Collecting sgmllib3k (from feedparser>=5.2.1->newspaper3k==0.2.8)\n",
      "  Downloading sgmllib3k-1.0.0.tar.gz (5.8 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting click (from nltk>=3.2.1->newspaper3k==0.2.8)\n",
      "  Downloading click-8.3.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting joblib (from nltk>=3.2.1->newspaper3k==0.2.8)\n",
      "  Downloading joblib-1.5.2-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting regex>=2021.8.3 (from nltk>=3.2.1->newspaper3k==0.2.8)\n",
      "  Downloading regex-2025.9.18-cp310-cp310-win_amd64.whl.metadata (41 kB)\n",
      "Requirement already satisfied: tqdm in c:\\users\\yunji\\anaconda3\\envs\\myenv\\lib\\site-packages (from nltk>=3.2.1->newspaper3k==0.2.8) (4.67.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\yunji\\anaconda3\\envs\\myenv\\lib\\site-packages (from requests>=2.10.0->newspaper3k==0.2.8) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\yunji\\anaconda3\\envs\\myenv\\lib\\site-packages (from requests>=2.10.0->newspaper3k==0.2.8) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\yunji\\anaconda3\\envs\\myenv\\lib\\site-packages (from requests>=2.10.0->newspaper3k==0.2.8) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\yunji\\anaconda3\\envs\\myenv\\lib\\site-packages (from requests>=2.10.0->newspaper3k==0.2.8) (2025.8.3)\n",
      "Collecting requests-file>=1.4 (from tldextract>=2.0.1->newspaper3k==0.2.8)\n",
      "  Downloading requests_file-2.1.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting filelock>=3.0.8 (from tldextract>=2.0.1->newspaper3k==0.2.8)\n",
      "  Downloading filelock-3.19.1-py3-none-any.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\yunji\\anaconda3\\envs\\myenv\\lib\\site-packages (from click->nltk>=3.2.1->newspaper3k==0.2.8) (0.4.6)\n",
      "Downloading newspaper3k-0.2.8-py3-none-any.whl (211 kB)\n",
      "Downloading cssselect-1.3.0-py3-none-any.whl (18 kB)\n",
      "Downloading feedparser-6.0.12-py3-none-any.whl (81 kB)\n",
      "Downloading lxml-6.0.2-cp310-cp310-win_amd64.whl (4.0 MB)\n",
      "   ---------------------------------------- 0.0/4.0 MB ? eta -:--:--\n",
      "   ------------------ --------------------- 1.8/4.0 MB 10.0 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 3.1/4.0 MB 8.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 4.0/4.0 MB 7.5 MB/s  0:00:00\n",
      "Downloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.5/1.5 MB 8.0 MB/s  0:00:00\n",
      "Downloading pillow-11.3.0-cp310-cp310-win_amd64.whl (7.0 MB)\n",
      "   ---------------------------------------- 0.0/7.0 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 1.3/7.0 MB 8.4 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 3.4/7.0 MB 9.6 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 5.5/7.0 MB 9.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  6.8/7.0 MB 8.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 7.0/7.0 MB 8.4 MB/s  0:00:00\n",
      "Downloading PyYAML-6.0.2-cp310-cp310-win_amd64.whl (161 kB)\n",
      "Downloading regex-2025.9.18-cp310-cp310-win_amd64.whl (276 kB)\n",
      "Downloading tldextract-5.3.0-py3-none-any.whl (107 kB)\n",
      "Downloading filelock-3.19.1-py3-none-any.whl (15 kB)\n",
      "Downloading requests_file-2.1.0-py2.py3-none-any.whl (4.2 kB)\n",
      "Downloading click-8.3.0-py3-none-any.whl (107 kB)\n",
      "Downloading joblib-1.5.2-py3-none-any.whl (308 kB)\n",
      "Building wheels for collected packages: tinysegmenter, feedfinder2, jieba3k, sgmllib3k\n",
      "  Building wheel for tinysegmenter (setup.py): started\n",
      "  Building wheel for tinysegmenter (setup.py): finished with status 'done'\n",
      "  Created wheel for tinysegmenter: filename=tinysegmenter-0.3-py3-none-any.whl size=13667 sha256=b96d7971ba095d143ebc4b574926568d40b52be2a65f9e2644cb4973712381bf\n",
      "  Stored in directory: c:\\users\\yunji\\appdata\\local\\pip\\cache\\wheels\\c8\\d6\\6c\\384f58df48c00b9a31d638005143b5b3ac62c3d25fb1447f23\n",
      "  Building wheel for feedfinder2 (setup.py): started\n",
      "  Building wheel for feedfinder2 (setup.py): finished with status 'done'\n",
      "  Created wheel for feedfinder2: filename=feedfinder2-0.0.4-py3-none-any.whl size=3409 sha256=57259ca703bda7c1326164b206623deab4bcaec1b9a5460745a21380093990a4\n",
      "  Stored in directory: c:\\users\\yunji\\appdata\\local\\pip\\cache\\wheels\\97\\02\\e7\\a1ff1760e12bdbaab0ac824fae5c1bc933e41c4ccd6a8f8edb\n",
      "  Building wheel for jieba3k (setup.py): started\n",
      "  Building wheel for jieba3k (setup.py): finished with status 'done'\n",
      "  Created wheel for jieba3k: filename=jieba3k-0.35.1-py3-none-any.whl size=7398410 sha256=c83f2b505319d55812c9e5d8a407ed9eb2c6561b96b354620a46fdb843fc3e0c\n",
      "  Stored in directory: c:\\users\\yunji\\appdata\\local\\pip\\cache\\wheels\\7a\\c4\\0c\\12a9a314ecac499456c4c3b2fcc2f635a3b45a39dfbd240299\n",
      "  Building wheel for sgmllib3k (setup.py): started\n",
      "  Building wheel for sgmllib3k (setup.py): finished with status 'done'\n",
      "  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6105 sha256=da9b75b9e1e4557799e40ba61bffcc6cb6c30b31a6d85dc5f50ade5337528fa3\n",
      "  Stored in directory: c:\\users\\yunji\\appdata\\local\\pip\\cache\\wheels\\f0\\69\\93\\a47e9d621be168e9e33c7ce60524393c0b92ae83cf6c6e89c5\n",
      "Successfully built tinysegmenter feedfinder2 jieba3k sgmllib3k\n",
      "Installing collected packages: tinysegmenter, sgmllib3k, jieba3k, regex, PyYAML, Pillow, lxml, joblib, filelock, feedparser, cssselect, click, requests-file, nltk, feedfinder2, tldextract, newspaper3k\n",
      "\n",
      "   ---- -----------------------------------  2/17 [jieba3k]\n",
      "   ---- -----------------------------------  2/17 [jieba3k]\n",
      "   ---- -----------------------------------  2/17 [jieba3k]\n",
      "   ---- -----------------------------------  2/17 [jieba3k]\n",
      "   ------- --------------------------------  3/17 [regex]\n",
      "   ----------- ----------------------------  5/17 [Pillow]\n",
      "   ----------- ----------------------------  5/17 [Pillow]\n",
      "   ----------- ----------------------------  5/17 [Pillow]\n",
      "   ----------- ----------------------------  5/17 [Pillow]\n",
      "   -------------- -------------------------  6/17 [lxml]\n",
      "   -------------- -------------------------  6/17 [lxml]\n",
      "   ---------------- -----------------------  7/17 [joblib]\n",
      "   ---------------- -----------------------  7/17 [joblib]\n",
      "   ---------------- -----------------------  7/17 [joblib]\n",
      "   --------------------- ------------------  9/17 [feedparser]\n",
      "   ------------------------- -------------- 11/17 [click]\n",
      "   ------------------------------ --------- 13/17 [nltk]\n",
      "   ------------------------------ --------- 13/17 [nltk]\n",
      "   ------------------------------ --------- 13/17 [nltk]\n",
      "   ------------------------------ --------- 13/17 [nltk]\n",
      "   ------------------------------ --------- 13/17 [nltk]\n",
      "   ------------------------------ --------- 13/17 [nltk]\n",
      "   ------------------------------ --------- 13/17 [nltk]\n",
      "   ------------------------------ --------- 13/17 [nltk]\n",
      "   ------------------------------ --------- 13/17 [nltk]\n",
      "   ------------------------------ --------- 13/17 [nltk]\n",
      "   ------------------------------ --------- 13/17 [nltk]\n",
      "   ------------------------------ --------- 13/17 [nltk]\n",
      "   ------------------------------------- -- 16/17 [newspaper3k]\n",
      "   ---------------------------------------- 17/17 [newspaper3k]\n",
      "\n",
      "Successfully installed Pillow-11.3.0 PyYAML-6.0.2 click-8.3.0 cssselect-1.3.0 feedfinder2-0.0.4 feedparser-6.0.12 filelock-3.19.1 jieba3k-0.35.1 joblib-1.5.2 lxml-6.0.2 newspaper3k-0.2.8 nltk-3.9.1 regex-2025.9.18 requests-file-2.1.0 sgmllib3k-1.0.0 tinysegmenter-0.3 tldextract-5.3.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  DEPRECATION: Building 'tinysegmenter' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'tinysegmenter'. Discussion can be found at https://github.com/pypa/pip/issues/6334\n",
      "  DEPRECATION: Building 'feedfinder2' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'feedfinder2'. Discussion can be found at https://github.com/pypa/pip/issues/6334\n",
      "  DEPRECATION: Building 'jieba3k' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'jieba3k'. Discussion can be found at https://github.com/pypa/pip/issues/6334\n",
      "  DEPRECATION: Building 'sgmllib3k' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'sgmllib3k'. Discussion can be found at https://github.com/pypa/pip/issues/6334\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lxml_html_clean\n",
      "  Downloading lxml_html_clean-0.4.2-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: lxml in c:\\users\\yunji\\anaconda3\\envs\\myenv\\lib\\site-packages (from lxml_html_clean) (6.0.2)\n",
      "Downloading lxml_html_clean-0.4.2-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: lxml_html_clean\n",
      "Successfully installed lxml_html_clean-0.4.2\n",
      "Requirement already satisfied: pandas in c:\\users\\yunji\\anaconda3\\envs\\myenv\\lib\\site-packages (2.3.2)\n",
      "Requirement already satisfied: numpy>=1.22.4 in c:\\users\\yunji\\anaconda3\\envs\\myenv\\lib\\site-packages (from pandas) (2.2.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\yunji\\anaconda3\\envs\\myenv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\yunji\\anaconda3\\envs\\myenv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\yunji\\anaconda3\\envs\\myenv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\yunji\\anaconda3\\envs\\myenv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install gdeltdoc\n",
    "!pip install newspaper3k==0.2.8\n",
    "!pip install lxml_html_clean\n",
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 라이브러리 임포트\n",
    "필요한 라이브러리를 코드에 임포트합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gdeltdoc import GdeltDoc, Filters\n",
    "from newspaper import Article\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. GDELT API 필터 설정\n",
    "\n",
    "GDELT API를 사용하여 원하는 기사를 추출하기 위한 필터를 설정합니다. Filters 클래스를 사용하여 날짜, 키워드, 도메인 등 다양한 조건을 지정할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = Filters(\n",
    "    keyword = \"Microsoft\",  # 키워드: Microsoft 관련 기사만 추출\n",
    "    start_date = \"2024-05-01\",  # 시작 날짜\n",
    "    end_date = \"2024-05-25\",  # 종료 날짜\n",
    "    num_records=10,  # 가져올 기사의 수\n",
    "    domain =\"nytimes.com\",  # 특정 도메인(여기서는 NYTimes)\n",
    "    country=\"US\",  # 국가 설정 (US)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. GDELT 데이터 검색\n",
    "\n",
    "설정한 필터에 맞는 기사를 GDELT API를 통해 검색하여 결과를 pandas DataFrame으로 변환합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The C . E . O . s Who Just Wont Quit - The New...</td>\n",
       "      <td>https://www.nytimes.com/2024/05/09/magazine/fo...</td>\n",
       "      <td>Of the many riddles that confront corporate ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C . Gordon Bell , Creator of a Personal Comput...</td>\n",
       "      <td>https://www.nytimes.com/2024/05/21/technology/...</td>\n",
       "      <td>C. Gordon Bell, a technology visionary whose c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wayve , an A . I . Start - Up for Autonomous D...</td>\n",
       "      <td>https://www.nytimes.com/2024/05/06/technology/...</td>\n",
       "      <td>Wayve, a London maker of artificial intelligen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Biden to Announce A . I . Center in Wisconsin ...</td>\n",
       "      <td>https://www.nytimes.com/2024/05/08/us/politics...</td>\n",
       "      <td>President Biden on Wednesday announced the cre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How Rich Candidates Burned Cash on Running for...</td>\n",
       "      <td>https://www.nytimes.com/2024/05/16/us/politics...</td>\n",
       "      <td>The costly realm of campaign politics has clai...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  The C . E . O . s Who Just Wont Quit - The New...   \n",
       "1  C . Gordon Bell , Creator of a Personal Comput...   \n",
       "2  Wayve , an A . I . Start - Up for Autonomous D...   \n",
       "3  Biden to Announce A . I . Center in Wisconsin ...   \n",
       "4  How Rich Candidates Burned Cash on Running for...   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://www.nytimes.com/2024/05/09/magazine/fo...   \n",
       "1  https://www.nytimes.com/2024/05/21/technology/...   \n",
       "2  https://www.nytimes.com/2024/05/06/technology/...   \n",
       "3  https://www.nytimes.com/2024/05/08/us/politics...   \n",
       "4  https://www.nytimes.com/2024/05/16/us/politics...   \n",
       "\n",
       "                                                text  \n",
       "0  Of the many riddles that confront corporate ch...  \n",
       "1  C. Gordon Bell, a technology visionary whose c...  \n",
       "2  Wayve, a London maker of artificial intelligen...  \n",
       "3  President Biden on Wednesday announced the cre...  \n",
       "4  The costly realm of campaign politics has clai...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GDELT 객체 생성\n",
    "gd = GdeltDoc()\n",
    "\n",
    "# 필터에 맞는 기사 검색\n",
    "articles = gd.article_search(f)\n",
    "\n",
    "# 기사의 URL과 제목을 포함한 DataFrame 생성\n",
    "articles_data = []\n",
    "for index, row in articles.iterrows():\n",
    "    url = row['url']\n",
    "    title = row['title']\n",
    "    \n",
    "    # Newspaper3k 라이브러리를 사용하여 기사 본문 추출\n",
    "    article = Article(url)\n",
    "    article.download()\n",
    "    article.parse()\n",
    "    text = article.text  # 기사 본문\n",
    "    \n",
    "    # DataFrame에 추가\n",
    "    articles_data.append({\n",
    "        \"title\": title,\n",
    "        \"url\": url,\n",
    "        \"text\": text\n",
    "    })\n",
    "\n",
    "# DataFrame 생성\n",
    "articles_df = pd.DataFrame(articles_data)\n",
    "\n",
    "# 결과 출력\n",
    "articles_df.head()  # 첫 5개의 기사 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. CSV 파일로 저장\n",
    "\n",
    "최종적으로 추출한 기사 데이터를 pandas DataFrame으로 저장한 후, 이를 CSV 파일로 저장합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV 파일로 저장\n",
    "articles_df.to_csv('articles_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
